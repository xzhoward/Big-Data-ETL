{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Assignment\n",
    "\n",
    "__Summary__\n",
    "\n",
    "Many of Amazon's shoppers depend on product reviews to make a purchase. \n",
    "Amazon makes these datasets publicly available. However, they are quite\n",
    "large and can exceed the capacity of local machines to handle. One dataset \n",
    "alone contains over 1.5 million rows.\n",
    "\n",
    "__Goal__\n",
    "\n",
    "Performing the `ETL process` completely `in the cloud` and upload a DataFrame\n",
    "to an `RDS instance`, from two Amazon customer review data sets.\n",
    "\n",
    "__Data sets__\n",
    "\n",
    "- Shoes s3a://amazon-reviews-pds/tsv/amazon_reviews_us_Shoes_v1_00.tsv.g\n",
    "\n",
    "- Apparel s3a://amazon-reviews-pds/tsv/amazon_reviews_us_Apparel_v1_00.tsv.gz\n",
    "\n",
    "\n",
    "__Notes__\n",
    "\n",
    "- Here is the code used in the Apache Zeppelin notebook to load the __Shoes__\n",
    "data set. Apache Zeppelin is a web-based notebook which brings data exploration, \n",
    "visualization, sharing and collaboration features to Spark.\n",
    "\n",
    "- Before loading the two data sets, a test was performed with a sample file,\n",
    "the first cells are showing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark import SparkFiles\n",
    "# Load a sample from S3 into a DataFrame\n",
    "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/sample_us.tsv\"\n",
    "\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "sample_usa_df = spark.read.option('header', 'true').csv(SparkFiles.get(\"sample_us.tsv\"), inferSchema=True, sep='\\t')\n",
    "sample_usa_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# See the data types to compare them with the required database schema\n",
    "sample_usa_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark import SparkFiles\n",
    "# Load a shoes data from S3 into a DataFrame\n",
    "\n",
    "shoes_df = spark.read.option('header', 'true').csv(\"s3a://amazon-reviews-pds/tsv/amazon_reviews_us_Shoes_v1_00.tsv.gz\", inferSchema=True, sep='\\t')\n",
    "shoes_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# review_date should be in the format yyyy-mm-dd\n",
    "#date_df = sample_usa_df.withColumn(\"date\", to_date(\"review_date\", \"yyyy-mm-dd\"))\n",
    "date_df = shoes_df.withColumn(\"date\", to_date(\"review_date\", \"yyyy-mm-dd\"))\n",
    "date_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark.sql.functions import col\n",
    "# Created data frame to match review_id_table\n",
    "# CREATE TABLE review_id_table (review_id TEXT PRIMARY KEY NOT NULL, customer_id INTEGER, product_id TEXT, product_parent INTEGER, \n",
    "# review_date DATE -- this should be in the formate yyyy-mm-dd );\n",
    "\n",
    "review_df = date_df.select([\"review_id\", \"customer_id\", \"product_id\", \"product_parent\", col(\"date\").alias(\"review_date\")])\n",
    "review_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Number of reviews\n",
    "review_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Created data frame to match products table  -- This table will contain only unique values\n",
    "# CREATE TABLE products (product_id TEXT PRIMARY KEY NOT NULL UNIQUE,product_title TEXT);\n",
    "products_df = date_df.select([\"product_id\", \"product_title\"]).distinct()\n",
    "products_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Number of products\n",
    "products_df.count()   # => 1901053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Created data frame to match customer table -- Customer table for first data set\n",
    "# CREATE TABLE customers (customer_id INT PRIMARY KEY NOT NULL UNIQUE,  customer_count INT);\n",
    "counts_df = date_df.groupBy(\"customer_id\").count().orderBy(\"customer_id\")\n",
    "counts_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Check the data types\n",
    "counts_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Number of customers\n",
    "customers_df.count()   # => 2816830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Created data frame to match vine table\n",
    "# CREATE TABLE vine_table (review_id TEXT PRIMARY KEY, star_rating INTEGER, helpful_votes INTEGER, total_votes INTEGER, vine TEXT);\n",
    "\n",
    "vine_df = date_df.select([\"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\"])\n",
    "vine_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Number of vines\n",
    "vine_df.count()  # => 4366916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Configure settings for RDS\n",
    "mode = \"append\"\n",
    "jdbc_url=\"jdbc:postgresql://<endpoiny>:<port>/<db>\"\n",
    "config = {\"user\":\"<user>\", \n",
    "          \"password\": \"<pwd>\", \n",
    "          \"driver\":\"org.postgresql.Driver\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Append DataFrame to review_id_table in RDS\n",
    "review_df.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reviews](../Images/rev_shoes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Write dataframe to products table in RDS\n",
    "products_df.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Products](../Images/prod_shoes.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Write dataframe to customers table in RDS\n",
    "customers_df.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Customer](../Images/cust_shoes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Write dataframe to vine_table table in RDS\n",
    "vine_df.write.jdbc(url=jdbc_url, table='vine_table', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Vine](../Images/vine_shoes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
