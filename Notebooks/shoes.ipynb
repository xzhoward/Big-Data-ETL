{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark import SparkFiles\n",
    "# Load a sample from S3 into a DataFrame\n",
    "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/sample_us.tsv\"\n",
    "\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "sample_usa_df = spark.read.option('header', 'true').csv(SparkFiles.get(\"sample_us.tsv\"), inferSchema=True, sep='\\t')\n",
    "sample_usa_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# See the data types to compare them with the required database schema\n",
    "sample_usa_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark import SparkFiles\n",
    "# Load a shoes data from S3 into a DataFrame\n",
    "\n",
    "shoes_df = spark.read.option('header', 'true').csv(\"s3a://amazon-reviews-pds/tsv/amazon_reviews_us_Shoes_v1_00.tsv.gz\", inferSchema=True, sep='\\t')\n",
    "shoes_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# review_date should be in the format yyyy-mm-dd\n",
    "#date_df = sample_usa_df.withColumn(\"date\", to_date(\"review_date\", \"yyyy-mm-dd\"))\n",
    "date_df = shoes_df.withColumn(\"date\", to_date(\"review_date\", \"yyyy-mm-dd\"))\n",
    "date_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark.sql.functions import col\n",
    "# Created data frame to match review_id_table\n",
    "# CREATE TABLE review_id_table (review_id TEXT PRIMARY KEY NOT NULL, customer_id INTEGER, product_id TEXT, product_parent INTEGER, \n",
    "# review_date DATE -- this should be in the formate yyyy-mm-dd );\n",
    "\n",
    "review_df = date_df.select([\"review_id\", \"customer_id\", \"product_id\", \"product_parent\", col(\"date\").alias(\"review_date\")])\n",
    "review_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Number of reviews\n",
    "review_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Created data frame to match products table  -- This table will contain only unique values\n",
    "# CREATE TABLE products (product_id TEXT PRIMARY KEY NOT NULL UNIQUE,product_title TEXT);\n",
    "products_df = date_df.select([\"product_id\", \"product_title\"]).distinct()\n",
    "products_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Number of products\n",
    "products_df.count()   # => 1901053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Created data frame to match customer table -- Customer table for first data set\n",
    "# CREATE TABLE customers (customer_id INT PRIMARY KEY NOT NULL UNIQUE,  customer_count INT);\n",
    "counts_df = date_df.groupBy(\"customer_id\").count().orderBy(\"customer_id\")\n",
    "counts_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Check the data types\n",
    "counts_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Number of customers\n",
    "customers_df.count()   # => 2816830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Created data frame to match vine table\n",
    "# CREATE TABLE vine_table (review_id TEXT PRIMARY KEY, star_rating INTEGER, helpful_votes INTEGER, total_votes INTEGER, vine TEXT);\n",
    "\n",
    "vine_df = date_df.select([\"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\"])\n",
    "vine_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Number of vines\n",
    "vine_df.count()  # => 4366916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Configure settings for RDS\n",
    "mode = \"append\"\n",
    "jdbc_url=\"jdbc:postgresql://<endpoiny>:<port>/<db>\"\n",
    "config = {\"user\":\"<user>\", \n",
    "          \"password\": \"<pwd>\", \n",
    "          \"driver\":\"org.postgresql.Driver\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Append DataFrame to review_id_table in RDS\n",
    "review_df.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Write dataframe to products table in RDS\n",
    "products_df.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Write dataframe to customers table in RDS\n",
    "customers_df.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "# Write dataframe to vine_table table in RDS\n",
    "vine_df.write.jdbc(url=jdbc_url, table='vine_table', mode=mode, properties=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
